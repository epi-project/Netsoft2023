{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>The graph initialisation</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"<h1>The graph initialisation</h1>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = {\"cluster1-cntx\":[\"cluster1-cntx\",\"cluster2-cntx\"], \"cluster2-cntx\":[\"cluster2-cntx\",\"cluster1-cntx\"]}#, \"cluster3-cntx\":[\"cluster3-cntx\"]}\n",
    "link_latency = {\"cluster1-cntx\":{\"cluster1-cntx\":0, \"cluster2-cntx\":10},\"cluster2-cntx\":{\"cluster2-cntx\":0, \"cluster1-cntx\":10}}\n",
    "                                 \n",
    "bf = {\"firewall\":{\"firewalls\":10, \"firewallm\":5, \"firewalll\":1}, \"encrypt\":{\"encrypts\":10, \"encryptm\":5, \"encryptl\":1}, \"decrypt\":{\"decrypts\":10, \"decryptm\":5, \"decryptl\":1}}\n",
    "\n",
    "#G = {\"cluster1-cntx\":[\"cluster1-cntx\", \"cluster2-cntx\"], \"cluster2-cntx\":[\"cluster2-cntx\", \"cluster1-cntx\"]}\n",
    "#link_latency = {\"cluster1-cntx\":{\"cluster1-cntx\":0, \"cluster2-cntx\":10, \"cluster3-cntx\":1000},\"cluster2-cntx\":{\"cluster2-cntx\":0, \"cluster1-cntx\":10, \"cluster3-cntx\":1000}, \"cluster3-cntx\":{\"cluster3-cntx\":0, \"cluster1-cntx\":1000,\"cluster2-cntx\":1000}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To generate different usecases under different requests \n",
    "\n",
    "G_req1 = {\"encrypt\":[\"firewall\"], \"firewall\":[\"encrypt\", \"decrypt\"], \"decrypt\":[\"firewall\"]}\n",
    "G_req2 = {\"firewall\":[\"encrypt\"], \"encrypt\":[\"firewall\", \"decrypt\"], \"decrypt\":[\"encrypt\"]}\n",
    "G_req3 = {\"encrypt\":[\"decrypt\"], \"decrypt\":[\"encrypt\"]}\n",
    "G_req4 = {\"encrypt\":[\"firewall\"], \"firewall\":[\"encrypt\"]}\n",
    "G_req5 = {\"firewall\":[\"firewall\"]}\n",
    "G_req6 = {\"encrypt\":[\"encrypt\"]}\n",
    "\n",
    "usecase = {\"EHR:1C:E-F-D\":{\"firewall\":30,\"encrypt\": 20, \"decrypt\":10, \"SLA\":100}, \"EHR:1C:F-E-D\":{\"firewall\":40, \"encrypt\": 10, \"decrypt\": 10, \"SLA\": 100}, \"EHR:1C:E-D\":{\"encrypt\": 20, \"decrypt\":20, \"SLA\":100}, \"EHR:1C:E-F\":{\"firewall\":30,\"encrypt\": 20, \"SLA\":100}, \"EHR:1C:E\":{\"encrypt\": 20, \"SLA\":100}, \"EHR:1C:F\":{\"firewall\":40, \"SLA\":100}, \"EHR:10C:E-F-D\":{\"firewall\":130,\"encrypt\": 80, \"decrypt\":20, \"SLA\":100}, \"EHR:10C:E\":{\"encrypt\": 80, \"SLA\":100}, \"EHR:10C:F-E-D\":{\"firewall\":160, \"encrypt\": 20, \"decrypt\":20, \"SLA\":100},\"EHR:10C:E-D\":{\"encrypt\": 80, \"decrypt\":80, \"SLA\":100}, \"EHR:10C:E-F\":{\"firewall\":130,\"encrypt\": 80, \"SLA\":100}, \"EHR:10C:F\":{\"firewall\":160,\"SLA\":100}, \"STREAM:1C:E-F-D\":{\"firewall\":130,\"encrypt\": 80, \"decrypt\":25, \"SLA\":10}, \"STREAM:1C:F-E-D\":{\"firewall\":180,\"encrypt\": 25, \"decrypt\": 25, \"SLA\": 10}, \"STREAM:1C:E-D\":{\"encrypt\": 80, \"decrypt\":80, \"SLA\":10}, \"STREAM:1C:E-F\":{\"firewall\":130,\"encrypt\": 80, \"SLA\":10}, \"STREAM:1C:F\":{\"firewall\":180, \"SLA\":10}, \"STREAM:10C:E-F-D\":{\"firewall\":300,\"encrypt\": 150, \"decrypt\":40, \"SLA\":10}, \"STREAM:10C:F-E-D\":{\"firewall\":350, \"encrypt\": 40, \"decrypt\":40, \"SLA\":10},\"STREAM:10C:E-D\":{\"encrypt\": 150, \"decrypt\":150, \"SLA\":10}, \"STREAM:10C:E-F\":{\"firewall\":300,\"encrypt\": 150, \"SLA\":10}, \"STREAM:10C:F\":{\"firewall\":350,\"SLA\":10}, \"ALGO:1C:E-F-D\":{\"firewall\":30,\"encrypt\": 20, \"decrypt\":10, \"SLA\":100}, \"ALGO:1C:F-E-D\":{\"firewall\":40,\"encrypt\": 10, \"decrypt\": 10, \"SLA\": 100}, \"ALGO:1C:E-D\":{\"encrypt\": 20, \"decrypt\":20, \"SLA\":100}, \"ALGO:1C:E-F\":{\"firewall\":30,\"encrypt\": 20, \"SLA\":100}, \"ALGO:1C:F\":{\"firewall\":40, \"SLA\":100}, \"ALGO:10C:E-F-D\":{\"firewall\":130,\"encrypt\": 80, \"decrypt\":20, \"SLA\":100}, \"ALGO:10C:F-E-D\":{\"firewall\":160, \"encrypt\": 20, \"decrypt\":20, \"SLA\":100},\"ALGO:10C:E-D\":{\"encrypt\": 80, \"decrypt\":80, \"SLA\":100}, \"ALGO:10C:E-F\":{\"firewall\":130,\"encrypt\": 80, \"SLA\":100}, \"ALGO:10C:F\":{\"firewall\":160,\"SLA\":100}}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encrypt': 20, 'SLA': 100}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#G_req = {\"firewall\":[\"encrypt\"], \"encrypt\":[\"firewall\"]}#, \"decrypt\":[\"firewall\"]}\n",
    "#usecase = {1:{\"firewall\":300,\"encrypt\": 300, \"decrypt\":300, \"SLA\":10}, 2:{\"firewall\":100,\"encrypt\": 100}, \"SLA\": 100}\n",
    "#u =1\n",
    "u = \"EHR:1C:E\"\n",
    "G_req=G_req6\n",
    "proxy=\"proxy4\"\n",
    "\n",
    "usecase[u]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cluster1-cntx', 'cluster2-cntx']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G[\"cluster1-cntx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>The graph illustration</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"<h1>The graph illustration</h1>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "\n",
    "def draw(G):\n",
    "    infra = nx.DiGraph()\n",
    " #   for cl in range(len(G)):\n",
    " #       i = list(G.keys())[cl]\n",
    " #       infra.add_node(i)\n",
    "    for cl in range(len(G)):\n",
    "        i = list(G.keys())[cl]\n",
    "        for link in range(len(G[i])):\n",
    "            infra.add_edges_from([(i, G[i][link])], weight=link_latency[i][G[i][link]])\n",
    "    edge_labels=dict([((u,v,),d['weight'])\n",
    "                 for u,v,d in infra.edges(data=True)])\n",
    "\n",
    "\n",
    "    pos = nx.spring_layout(infra)\n",
    "    nx.draw_networkx_edge_labels(infra,pos,edge_labels=edge_labels)\n",
    "    nx.draw_networkx_labels(infra, pos)\n",
    "    #plt.figure(figsize=(8,8))\n",
    "    \n",
    "    nx.draw(infra, pos=pos, with_labels=True)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "draw(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The number of running pods of a microservice on each cluster\n",
    "import os\n",
    "def runningPods(cluster, app_name): \n",
    "    output = os.popen('sudo kubectl top pod --context=' + cluster).read()\n",
    "    lines = output.split(\"\\n\")\n",
    "    numPods = 0\n",
    "    which_app = len(app_name)\n",
    "    for line in lines[:-1]:\n",
    "        items = line.split()\n",
    "        if len(items[0]) > 8 and items[0][:which_app] == app_name:\n",
    "            numPods += 1\n",
    "    return numPods\n",
    "runningPods(\"cluster1-cntx\",\"encrypt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The utilised CPU of a microservice running on a cluster\n",
    "import os\n",
    "def getchar(string, n):\n",
    "    return str(string)[n - 1]\n",
    "def cpuUtilised(cluster, app_name):\n",
    "    output = os.popen('kubectl top pod --context=' + cluster).read()\n",
    "    lines = output.split(\"\\n\")\n",
    "    which_app = len(app_name)\n",
    "    cpu = ''\n",
    "    cpu_u=0\n",
    "    limits=0\n",
    "    for line in lines[:-1]:\n",
    "        items = line.split()\n",
    "        if items[0][:which_app] == app_name:\n",
    "            if getchar(items[0], which_app) == 's':\n",
    "                cpu = items[1]\n",
    "                cpu = cpu[:-1]\n",
    "                cpu = int(cpu)\n",
    "                cpu_u=cpu_u + cpu\n",
    "            if getchar(items[0], which_app) == 'm':\n",
    "                cpu = items[1]\n",
    "                cpu = cpu[:-1]\n",
    "                cpu = int(cpu)\n",
    "                cpu_u=cpu_u + cpu\n",
    "            if getchar(items[0], which_app) == 'l':\n",
    "                cpu = items[1]\n",
    "                cpu = cpu[:-1]\n",
    "                cpu = int(cpu)\n",
    "                cpu_u=cpu_u + cpu\n",
    "\n",
    "        \n",
    "                \n",
    "#    print(limits - cpu_u)\n",
    "    return cpu_u\n",
    "\n",
    "\n",
    "cpuUtilised(\"cluster1-cntx\",\"firewall\"+'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The available CPU of a microservice running on a cluster\n",
    "import os\n",
    "def getchar(string, n):\n",
    "    return str(string)[n - 1]\n",
    "def cpuAvail(cluster, app_name):\n",
    "    output = os.popen('kubectl top pod --context=' + cluster).read()\n",
    "    lines = output.split(\"\\n\")\n",
    "    which_app = len(app_name)\n",
    "    cpu = ''\n",
    "    cpu_u=0\n",
    "    limits=0\n",
    "    for line in lines[:-1]:\n",
    "        items = line.split()\n",
    "        if items[0][:which_app] == app_name:\n",
    "            if getchar(items[0], which_app) == 's':\n",
    "                limits = 100\n",
    "                cpu = items[1]\n",
    "                cpu = cpu[:-1]\n",
    "                cpu = int(cpu)\n",
    "                cpu_u=cpu_u + cpu\n",
    "            if getchar(items[0], which_app) == 'm':\n",
    "                limits = 200\n",
    "                cpu = items[1]\n",
    "                cpu = cpu[:-1]\n",
    "                cpu = int(cpu)\n",
    "                cpu_u=cpu_u + cpu\n",
    "            if getchar(items[0], which_app) == 'l':\n",
    "                limits = 500\n",
    "                cpu = items[1]\n",
    "                cpu = cpu[:-1]\n",
    "                cpu = int(cpu)\n",
    "                cpu_u=cpu_u + cpu\n",
    "\n",
    "        \n",
    "                \n",
    "#    print(limits - cpu_u)\n",
    "    return limits - cpu_u\n",
    "\n",
    "\n",
    "cpuAvail(\"cluster1-cntx\",\"firewall\"+'s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Which microservice configuration is running: small, medium, or large\n",
    "def getchar(string, n):\n",
    "    return str(string)[n - 1]\n",
    "def whichConf(cluster, app_name):\n",
    "    size = []\n",
    "    output = os.popen('sudo kubectl get services --context=' + cluster).read()\n",
    "    lines = output.split(\"\\n\")\n",
    "    which_app = len(app_name)\n",
    "    for line in lines[:-1]:\n",
    "        items = line.split()\n",
    "        if items[0][:which_app] == app_name:\n",
    "            size.append(getchar(items[0], which_app+1))\n",
    "    #        print(size)\n",
    "    return size\n",
    "whichConf(\"cluster1-cntx\",\"firewall\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>Monitor and delete function</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"<h1>Monitor and delete function</h1>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread is starting\n",
      "firewallm timed out\n"
     ]
    }
   ],
   "source": [
    "#This function is terminate services once idle for a time \n",
    "import threading\n",
    "import time\n",
    "import os\n",
    "\n",
    "def deletePod(app_name, timer, cluster):\n",
    "    print(\"thread is starting\")\n",
    "    cpu = 0\n",
    "    timeout = time.time() + timer\n",
    "    while cpu == 0:\n",
    "        cpu= cpuUtilised(cluster, app_name)\n",
    "        if time.time() > timeout:\n",
    "            try:\n",
    "                os.system(\"sudo kubectl delete service \"+ app_name +\" --context=\" + cluster)\n",
    "                os.system(\"sudo kubectl delete deploy \"+ app_name +\" --context=\" + cluster)\n",
    "                print(app_name+ \" timed out\")\n",
    "                break\n",
    "            except:\n",
    "                print(\"Service not found\")\n",
    "                break\n",
    "        \n",
    "def monitorUsage(cluster, timer):\n",
    "    for service in range(len(bf)):\n",
    "        threads = list()\n",
    "        ser = list(bf.keys())[service]\n",
    "        s = whichConf(cluster,ser)\n",
    "        if s != []:\n",
    "            for size in range(len(s)):\n",
    "                app_name=ser+s[size]\n",
    "                x =threading.Thread(target=deletePod, args=(app_name, timer, cluster,))\n",
    "                x.daemon = True\n",
    "                threads.append(x)\n",
    "                x.start()\n",
    "            for x in threads:\n",
    "                x.join()\n",
    "\n",
    "        \n",
    "monitorUsage(\"cluster3-cntx\",10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This function orders the running microservies on a cluster increasingly according to proccessing delay\n",
    "def orderService(cluster, app_name):\n",
    "    delay = []\n",
    "    size = whichConf(cluster, app_name)\n",
    "    for s in range(len(size)):\n",
    "        delay.append(bf[app_name][app_name+size[s]])\n",
    "    sorted_delay = [x for _,x in sorted(zip(delay,size))]\n",
    "    return sorted_delay\n",
    " #   print(delay)\n",
    "                \n",
    "    \n",
    "orderService(\"cluster2-cntx\",\"firewall\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "':'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "def getIP(cluster, app_name):\n",
    "    output = os.popen('sudo kubectl get pods -o wide --context=' + cluster).read()\n",
    "    lines = output.split(\"\\n\")\n",
    "    serviceIP = ''\n",
    "    port=''\n",
    "    which_app = len(app_name)\n",
    "    for line in lines[:-1]:\n",
    "        items = line.split()\n",
    "        if items[0][:which_app] == app_name:\n",
    "            serviceIP=items[5] \n",
    "    output = os.popen('sudo kubectl get service -o wide --context=' + cluster).read()\n",
    "    lines = output.split(\"\\n\")\n",
    "    which_app = len(app_name)\n",
    "    for line in lines[:-1]:\n",
    "        items = line.split()\n",
    "        if items[0][:which_app] == app_name:\n",
    "            port=items[4][:4]\n",
    "    serviceIP=serviceIP+\":\"+port\n",
    "    return serviceIP\n",
    "getIP(\"cluster2-cntx\",\"firewall\"+\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cluster2-cntx': ['cluster2-cntx', 'cluster1-cntx'],\n",
       " 'cluster1-cntx': ['cluster1-cntx', 'cluster2-cntx']}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This function orders the available links from source cluster increasingly according to latency\n",
    "def orderlink(cluster):\n",
    "    delay = []\n",
    "    cnx = []\n",
    "    for key in range(len(list(link_latency[cluster].keys()))):\n",
    "        delay.append(link_latency[cluster][list(link_latency[cluster].keys())[key]])\n",
    "        cnx.append(list(link_latency[cluster].keys())[key])\n",
    "    sorted_delay = [x for _,x in sorted(zip(delay,cnx))]\n",
    "    order_cluster = dict.fromkeys(sorted_delay, None)\n",
    "    \n",
    "    for i in range(len(sorted_delay)):\n",
    "        order_cluster[sorted_delay[i]] = G[sorted_delay[i]]\n",
    "        \n",
    "    return order_cluster\n",
    " #   print(delay)\n",
    "                \n",
    "    \n",
    "orderlink(\"cluster2-cntx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'something': 1}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test={\"something\": None}\n",
    "test[\"something\"]= 1\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3802"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Available CPU on a cluster in millicores\n",
    "def clusterCPU(cluster):\n",
    "    cpu=0\n",
    "    cpu_cl=0\n",
    "    nodes=0\n",
    "    output = os.popen('sudo kubectl top nodes --context=' + cluster).read()\n",
    "    lines = output.split(\"\\n\")\n",
    "    for line in lines[:-1]:\n",
    "        items = line.split()\n",
    "        if items[0] != \"NAME\":\n",
    "            cpu = items[1]\n",
    "            cpu = cpu[:-1]\n",
    "            cpu = int(cpu)\n",
    "            cpu_cl = cpu_cl + cpu\n",
    "            nodes=nodes+1\n",
    "    return nodes*2000 - cpu_cl\n",
    "\n",
    "clusterCPU('cluster1-cntx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Available CPU percentage on a cluster in\n",
    "def clusterCPUPerc(cluster):\n",
    "    cpu=0\n",
    "    cpu_cl=0\n",
    "    nodes=0\n",
    "    output = os.popen('sudo kubectl top nodes --context=' + cluster).read()\n",
    "    lines = output.split(\"\\n\")\n",
    "    for line in lines[:-1]:\n",
    "        items = line.split()\n",
    "        if items[0] != \"NAME\":\n",
    "            cpu = items[2]\n",
    "            cpu = cpu[:-1]\n",
    "            cpu = int(cpu)\n",
    "            cpu_cl = cpu_cl + cpu\n",
    "            nodes=nodes+1\n",
    "    #        print(size)\n",
    "    return cpu_cl/nodes\n",
    "\n",
    "clusterCPUPerc('cluster2-cntx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1549"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Available memory on a cluster in MB\n",
    "def clusterMem(cluster):\n",
    "    mem=0\n",
    "    mem_cl=0\n",
    "    nodes=0\n",
    "    output = os.popen('sudo kubectl top nodes --context=' + cluster).read()\n",
    "    lines = output.split(\"\\n\")\n",
    "    for line in lines[:-1]:\n",
    "        items = line.split()\n",
    "        if items[0] != \"NAME\":\n",
    "            mem = items[3]\n",
    "            mem = mem[:len(mem)-2]\n",
    "            nodes=nodes+1\n",
    "            mem = int(mem)\n",
    "            mem_cl = mem_cl + mem\n",
    "    #print(nodes)\n",
    "    #print(mem_cl)\n",
    "    return nodes*1915 - mem_cl\n",
    "\n",
    "clusterMem('cluster2-cntx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>Place and Assign new mircroservice to requests</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"<h1>Place and Assign new mircroservice to requests</h1>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def place(i, q, s):\n",
    "#    i = 'cluster2-cntx'\n",
    "    if s == 's':\n",
    "        os.system('sudo kubectl apply -f ~/SOCKS-deployement/'+q+'-S.yaml --context=' + i)\n",
    "    elif s == 'm':\n",
    "        os.system('sudo kubectl apply -f ~/SOCKS-deployement/'+q+'-M.yaml --context=' + i)\n",
    "    elif s == 'l':\n",
    "        os.system('sudo kubectl apply -f ~/SOCKS-deployement/'+q+'-L.yaml --context=' + i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignService(i, q, usecase_s, u):\n",
    "#    req = 1\n",
    "#    cl = 1\n",
    "    proxy_conf='' \n",
    "    size=[]\n",
    "    avail=0\n",
    "    cpu_q= usecase_s[u][q]\n",
    "    r = runningPods(i, q)\n",
    "    if r >= 1: #there's a function already running on this cluster \n",
    "        size = orderService(i,q) #which function size is running? order by delay\n",
    "        for s in range(len(size)): \n",
    "            avail = cpuAvail(i, q+size[s]) #the available CPU depends on the service configuration\n",
    "            if avail > cpu_q: #if the available resources > profiled resources requested \n",
    "                proxy_conf=getIP(i,q+size[s]) #then get IP to assign the service to proxy\n",
    "                break\n",
    "    elif r ==0 : #no service running \n",
    "        proxy_conf=''          \n",
    "    #print(proxy_conf)\n",
    "    return proxy_conf\n",
    "\n",
    "def newService(i,q, usecase_s, u):\n",
    "    proxy_conf=''\n",
    "    cpu_q= usecase_s[u][q]\n",
    "    r = runningPods(i, q)\n",
    "    if 600 > cpu_q and runningPods(i, q+'s') == 0 and 600 < clusterCPU(i): #deploy new small service\n",
    "        place(i,q,'s')\n",
    "        proxy_conf=getIP(i,q+'s')       \n",
    "    elif 5*600 > cpu_q and runningPods(i, q+'m')==0 and 5*600 < clusterCPU(i): #deploy new medium service\n",
    "        proxy_conf=getIP(i,q+'m')\n",
    "        proxy_conf=getIP(i,q+'m')\n",
    "    elif 10*600 > cpu_q and runningPods(i, q+'l')==0 and 10*600 < clusterCPU(i): #deploy new large service\n",
    "        proxy_conf=getIP(i,q+'l')\n",
    "        proxy_conf=getIP(i,q+'l')\n",
    "  #  elif proxy_conf=='':\n",
    "  #      print(\"placement failed\")\n",
    "        \n",
    "    \n",
    "    #print(proxy_conf)\n",
    "    return proxy_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cluster2-cntx']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Returns the lists of clusters on which a microservice type is running\n",
    "def checkdeploy(app_name):\n",
    "    cl = 0\n",
    "    p=0\n",
    "    cluster=[]\n",
    "    while p == 0:\n",
    "        for cl in range(len(G)):\n",
    "            i = list(G.keys())[cl]\n",
    "            output = os.popen('sudo kubectl get services --context=' +i).read()\n",
    "            lines = output.split(\"\\n\")\n",
    "            which_app = len(app_name)\n",
    "            for line in lines[:-1]:\n",
    "                items = line.split()\n",
    "                if items[0][:which_app] == app_name:\n",
    "                    cluster.append(i)\n",
    "                    p=1\n",
    "                    \n",
    "    return cluster\n",
    "checkdeploy(\"proxy4\")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def proxyConfig(IP, proxy):\n",
    "    newChain = []\n",
    "    for ip in range(len(IP)):\n",
    "        newChain.append('\"-c\",'+'\"socks6://'+IP[ip]+'\",')\n",
    "    newChain = ''.join(newChain)\n",
    "    newChain = newChain[:-1]\n",
    "    print(newChain)\n",
    "    os.system(\"sudo kubectl patch deployment \"+ proxy +\" --namespace default --type='json' -p='[{'op': 'replace', 'path': '/spec/template/spec/containers/0/args', 'value': [\"+newChain+\"]}]'\"+\" --context=\"+checkdeploy(proxy)[0])\n",
    "    \n",
    "proxyConfig(\"\", \"proxy0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cluster2-cntx']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkdeploy(\"proxy4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cluster2-cntx': ['cluster2-cntx', 'cluster1-cntx'], 'cluster1-cntx': ['cluster1-cntx', 'cluster2-cntx']}\n",
      "cluster2-cntx\n",
      "cluster1-cntx\n"
     ]
    }
   ],
   "source": [
    "OG = orderlink(checkdeploy(\"proxy4\")[0])\n",
    "print(OG)\n",
    "for cl in range(len(OG)): #go over clusters \n",
    "    i = list(OG.keys())[cl]\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster2-cntx\n",
      "cluster1-cntx\n",
      "\"-c\",\"socks6://10.0.0.21:1080\"\n",
      "['10.0.0.21:1080']\n",
      "['encrypt']\n"
     ]
    }
   ],
   "source": [
    "def main(proxy, G_req, u):\n",
    "    IPs = []\n",
    "    m_cl= ''\n",
    "    m_ser=[]\n",
    "    proxy_idx=proxy\n",
    "    startingCluster = checkdeploy(proxy_idx)[0]\n",
    "    OG = orderlink(startingCluster) #try the fastest link first\n",
    "    for cl in range(len(OG)): #go over clusters \n",
    "        i = list(OG.keys())[cl]\n",
    "        print(i)\n",
    "        for req in range(len(G_req)):\n",
    "            q = list(G_req.keys())[req] #go over functions to deploy\n",
    "            if req == 0 and q not in m_ser: #The first function can be deployed on any cluster\n",
    "                if assignService(i,q, usecase, u) != \"\": #there is atleast one good candidate service running on i \n",
    "                    IPs.append(assignService(i,q, usecase, u))\n",
    "                    m_cl= i #to check connection with next deployment\n",
    "                    m_ser.append(q)\n",
    "                    continue                \n",
    "            elif m_cl in G[i] and q not in m_ser: #connection with previous bf and not already deployed\n",
    "                if assignService(i,q, usecase, u) != \"\": #can be deployed\n",
    "                    IPs.append(assignService(i,q, usecase, u))\n",
    "                    m_cl= i\n",
    "                    m_ser.append(q)\n",
    "                    continue\n",
    "        if len(m_ser) < len(G_req): #not all deployed yet we try a different cluster      \n",
    "            continue \n",
    "        else:\n",
    "            break\n",
    "    if len(m_ser) < len(G_req): #not all functions could be deployed \n",
    "        for cl in range(len(OG)): #go over clusters \n",
    "            i = list(OG.keys())[cl]\n",
    "            for req in range(len(G_req)):\n",
    "                q = list(G_req.keys())[req] #go over functions to deploy\n",
    "                if req == 0 and q not in m_ser:\n",
    "                    if newService(i,q, usecase,u ) != '':\n",
    "                        IPs.append(newService(i,q, usecase, u))\n",
    "                        m_cl= i\n",
    "                        m_ser.append(q)\n",
    "                        continue\n",
    "                elif m_cl in G[i] and q not in m_ser: #connection with previous bf and not already deployed\n",
    "                        if newService(i,q, usecase, u) != '':\n",
    "                            IPs.append(newService(i,q, usecase, u))\n",
    "                            m_cl= i\n",
    "                            m_ser.append(q)\n",
    "                            continue\n",
    " #   if len(m_ser) == len(G_req):\n",
    " #       success = 1\n",
    " #       return success\n",
    " #   else: \n",
    " #       success =0\n",
    "        \n",
    "    time.sleep(15)   \n",
    "    proxyConfig(IPs, proxy)\n",
    "    print(IPs)\n",
    "    print(m_ser)\n",
    "    \n",
    "main(proxy, G_req, u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>Deploy and monitor microservices</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"<h1>Deploy and monitor microservices</h1>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = list()\n",
    "x =ThreadWithResult(target=main)\n",
    "x.daemon = True\n",
    "x.start()\n",
    "threads.append(x)\n",
    "for cl in range(len(G)): #go over clusters \n",
    "        i = list(G.keys())[cl]\n",
    "        x = ThreadWithResult(target=monitorUsage, args=(i,5, ))\n",
    "        x.daemon = True\n",
    "        threads.append(x)\n",
    "        x.start()\n",
    "for x in threads:\n",
    "    x.join()\n",
    "    print(x.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"<h1>Running requests</h1>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#whichGreq(u):\n",
    "#    return G_req\n",
    "\n",
    "#selectRandomu():\n",
    "#    random(u ) #every 1 min until 10 Greq\n",
    "#    main()\n",
    "#    calculate req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
